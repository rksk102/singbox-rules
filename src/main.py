import os
import json
import shutil
import tempfile
import re
import sys
import time
import subprocess
from datetime import timedelta
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- å°è¯•å¯¼å…¥ Rich åº“ ---
try:
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
    from rich.panel import Panel
    from rich.table import Table
    from rich import box
    from rich import print as rprint
except ImportError:
    print("Error: Please install rich (pip install rich)")
    sys.exit(1)

# å…¨å±€é…ç½®
console = Console(record=True)
ROOT_DIR = Path.cwd()
CONFIG_FILE = ROOT_DIR / "repos.json"
DIR_TXT = ROOT_DIR / "rules-txt"
DIR_JSON = ROOT_DIR / "rules-json"
DIR_SRS = ROOT_DIR / "rules-srs"
MAX_WORKERS = 4

# --- é¢„ç¼–è¯‘æ­£åˆ™ ---
REGEX_IP = re.compile(r'^(?:(?:[0-9]{1,3}\.){3}[0-9]{1,3}(?:/\d+)?)|(?:.*:.*)$')

# --- ç»Ÿè®¡æ•°æ®ç±» ---
class WorkflowStats:
    def __init__(self):
        self.start_time = time.time()
        self.sync_success = 0
        self.sync_total = 0
        self.compile_success = 0
        self.compile_fail = 0
        self.total_rules = 0
        self.details = [] 
        self.status = "âœ… æˆåŠŸ"

    @property
    def duration(self):
        return str(timedelta(seconds=int(time.time() - self.start_time)))

stats = WorkflowStats()

# --- è¾…åŠ©å‡½æ•° ---
def write_github_summary():
    if "GITHUB_STEP_SUMMARY" not in os.environ:
        return

    md_content = f"""
# ğŸš€ æ„å»ºæŠ¥å‘Š: {stats.status}

| æŒ‡æ ‡ | ç»“æœ |
| :--- | :--- |
| â±ï¸ è€—æ—¶ | {stats.duration} |
| ğŸ”„ åŒæ­¥ä»“åº“ | {stats.sync_success} / {stats.sync_total} |
| ğŸ”¨ ç¼–è¯‘æ–‡ä»¶ | {stats.compile_success} (å¤±è´¥: {stats.compile_fail}) |
| ğŸ“Š è§„åˆ™æ€»æ¡æ•° | **{stats.total_rules:,}** |

### ğŸ“‚ ç¼–è¯‘è¯¦æƒ… (Top 20)
| æ–‡ä»¶å | ç±»å‹ | è§„åˆ™æ•° |
| :--- | :--- | :---: |
"""
    sorted_details = sorted(stats.details, key=lambda x: x[2], reverse=True)[:20]
    for name, rtype, count in sorted_details:
        icon = "ğŸŒ" if rtype == "domain_suffix" else "ğŸ“¡"
        md_content += f"| {name} | {icon} `{rtype}` | {count:,} |\n"

    with open(os.environ["GITHUB_STEP_SUMMARY"], "a", encoding="utf-8") as f:
        f.write(md_content)

def handle_error(phase, error_msg):
    stats.status = f"âŒ å¤±è´¥äº {phase}"
    console.print(f"\n[bold red]â›” è‡´å‘½é”™è¯¯ - {phase}[/bold red]")
    console.print(Panel(str(error_msg), style="red", title="é”™è¯¯è¯¦æƒ…"))
    write_github_summary()
    sys.exit(1)

def flatten_directory(target_dir):
    """
    æš´åŠ›å¹³é“ºï¼š
    å¦‚æœ target_dir ä¸‹é¢æœ‰åä¸º rulesets æˆ– ruleset çš„æ–‡ä»¶å¤¹ï¼Œ
    å°†é‡Œé¢çš„å†…å®¹å…¨éƒ¨ç§»åŠ¨åˆ° target_dirï¼Œå¹¶åˆ é™¤è¯¥æ–‡ä»¶å¤¹ã€‚
    """
    problematic_names = ["rulesets", "ruleset"]
    
    # éå†å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰å­é¡¹
    # ä½¿ç”¨ list() æ˜¯å› ä¸ºæˆ‘ä»¬åœ¨è¿­ä»£è¿‡ç¨‹ä¸­å¯èƒ½ä¼šä¿®æ”¹ç›®å½•ç»“æ„
    for item in list(target_dir.iterdir()): 
        if item.is_dir() and item.name.lower() in problematic_names:
            console.print(f"[dim]  ğŸ§¹ æ­£åœ¨ç§»é™¤å¤šä½™å±‚çº§: {item.name}...[/dim]")
            
            # ç§»åŠ¨å­æ–‡ä»¶/æ–‡ä»¶å¤¹åˆ°ä¸Šä¸€å±‚ (target_dir)
            for sub_item in item.iterdir():
                dst_path = target_dir / sub_item.name
                
                # å¦‚æœç›®æ ‡å­˜åœ¨ï¼Œå…ˆåˆ é™¤ç›®æ ‡ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
                if dst_path.exists():
                    if dst_path.is_dir(): shutil.rmtree(dst_path)
                    else: dst_path.unlink()
                
                shutil.move(str(sub_item), str(dst_path))
            
            # åˆ æ‰é‚£ä¸ªç©ºçš„ rulesets æ–‡ä»¶å¤¹
            shutil.rmtree(item)

# --- æ ¸å¿ƒé€»è¾‘ ---

def init_workspace():
    console.rule("[bold blue]é˜¶æ®µ 1: åˆå§‹åŒ–å·¥ä½œåŒº[/bold blue]")
    try:
        dirs = [DIR_TXT, DIR_JSON, DIR_SRS]
        created = []
        for d in dirs:
            # 1. å¼ºåˆ¶æ¸…ç†ï¼šå¦‚æœå­˜åœ¨ï¼Œç›´æ¥åˆ æ‰æ•´ä¸ªæ–‡ä»¶å¤¹
            if d.exists(): 
                shutil.rmtree(d)
                console.print(f"[dim]  ğŸ—‘ï¸  å·²åˆ é™¤æ—§ç›®å½•: {d.name}[/dim]")
            # 2. é‡æ–°åˆ›å»º
            d.mkdir(parents=True)
            created.append(d.name)
        console.print(f"[green]âœ… å·¥ä½œåŒºå‡†å¤‡å°±ç»ª[/green]")
    except Exception as e:
        handle_error("åˆå§‹åŒ–", e)

def run_sync_phase():
    console.rule("[bold blue]é˜¶æ®µ 2: åŒæ­¥è¿œç¨‹æº[/bold blue]")
    
    if not CONFIG_FILE.exists():
        handle_error("é…ç½®è¯»å–", f"æ‰¾ä¸åˆ° {CONFIG_FILE}")

    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            repo_list = json.load(f)
            stats.sync_total = len(repo_list)
    except Exception as e:
        handle_error("é…ç½®è§£æ", e)

    sync_table = Table(box=box.SIMPLE_HEAD)
    sync_table.add_column("ä»“åº“", style="cyan")
    sync_table.add_column("ä¿®æ­£æ“ä½œ", style="dim")
    sync_table.add_column("çŠ¶æ€", justify="right")

    for item in repo_list:
        name = item.get('name', 'Unknown')
        with console.status(f"[bold yellow]â¬‡ï¸ æ­£åœ¨æ‹‰å–: {name}...[/bold yellow]"):
            try:
                url = item.get('url')
                remote_tgt = item.get('remote_path')
                # å»ºè®® local_subdir è®©ç”¨æˆ·ç•™ç©ºï¼Œæˆ–è€…è®¾ç½®ä¸ºå…·ä½“åˆ†ç±»åï¼ˆé™¤éä½ æƒ³å«å®ƒ rulesetsï¼‰
                local_sub = item.get('local_subdir', '') 
                
                dest_dir = DIR_TXT / local_sub
                dest_dir.mkdir(parents=True, exist_ok=True)

                with tempfile.TemporaryDirectory() as temp_dir:
                    # 1. Git æ‹‰å–
                    subprocess.run(["git", "clone", "--depth", "1", "--filter=blob:none", "--sparse", url, temp_dir],
                                   check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
                    subprocess.run(["git", "sparse-checkout", "set", remote_tgt],
                                   cwd=temp_dir, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
                    subprocess.run(["git", "checkout"],
                                   cwd=temp_dir, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
                    
                    full_remote_path = Path(temp_dir) / remote_tgt

                    # 2. å¤åˆ¶å†…å®¹åˆ°ç›®æ ‡ (ä¸ç®¡é‡Œé¢ç»“æ„å¤šä¹±ï¼Œå…ˆå…¨éƒ¨æ‹·è¿‡å»)
                    if full_remote_path.is_dir():
                        shutil.copytree(full_remote_path, dest_dir, dirs_exist_ok=True)
                    elif full_remote_path.is_file():
                        shutil.copy2(full_remote_path, dest_dir)
                    else:
                        raise FileNotFoundError(f"è¿œç¨‹è·¯å¾„ä¸å­˜åœ¨: {remote_tgt}")
                
                # â¤â¤â¤ æ­¥éª¤ 3: æš´åŠ›æ‰å¹³åŒ–å¤„ç† (The Flatten Strategy) â¤â¤â¤
                flatten_directory(dest_dir) 
                
                stats.sync_success += 1
                sync_table.add_row(name, f"å·²æ¸…ç†è‡³ {local_sub if local_sub else 'æ ¹ç›®å½•'}", "[green]OK[/green]")
            except Exception as e:
                sync_table.add_row(name, str(e), "[red]FAIL[/red]")
                handle_error(f"åŒæ­¥ [{name}]", e)

    console.print(sync_table)

def compile_file_worker(args):
    file_path, rel_path = args
    if not file_path.name.lower().endswith(('.txt', '.list', '.yaml', '.conf', '.json', '')):
        return None

    # å†…å®¹æ¸…æ´—
    raw_rules = set()
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                c = line.split('#')[0].split('//')[0].strip()
                if not c or c.startswith("payload:") or "repo" in c: continue
                c = c.replace("'", "").replace('"', "").replace(",", "").lstrip("-").strip()
                if c: raw_rules.add(c)
    except:
        return None
    
    if not raw_rules: return None
    rules_list = list(raw_rules)

    # è¯†åˆ«ç±»å‹
    fname = file_path.name.lower()
    if "ip" in fname and "domain" not in fname: 
        rtype = "ip_cidr"
    elif "domain" in fname or "site" in fname:
        rtype = "domain_suffix"
    else:
        sample = rules_list[:10]
        ip_cnt = sum(1 for x in sample if re.match(r'^\d+\.|:', x))
        rtype = "ip_cidr" if ip_cnt > len(sample)/2 else "domain_suffix"

    # è„æ•°æ®è¿‡æ»¤
    final_rules = []
    if rtype == "ip_cidr":
        for r in rules_list:
            if REGEX_IP.match(r) and "inverse" not in r and "arpa" not in r:
                final_rules.append(r)
    else:
        final_rules = rules_list

    if not final_rules: return None

    # è¾“å‡ºè·¯å¾„: æ­¤æ—¶ rules-txt ç»“æ„å·²ç»æ˜¯å¹³æ•´çš„äº†ï¼Œæ‰€ä»¥ç›´æ¥ç”¨ rel_path å³å¯
    # ä½†ä¸ºäº†ä»¥é˜²ä¸‡ä¸€ï¼Œè¿˜æ˜¯ä¿ç•™å» rulesets çš„é€»è¾‘
    path_parts = rel_path.parts
    if path_parts[0] in ["rulesets", "ruleset"]:
        clean_rel_path = Path(*path_parts[1:]) 
    else:
        clean_rel_path = rel_path

    out_dir_json = DIR_JSON / clean_rel_path.parent
    out_dir_srs = DIR_SRS / clean_rel_path.parent
    out_dir_json.mkdir(parents=True, exist_ok=True)
    out_dir_srs.mkdir(parents=True, exist_ok=True)

    json_path = out_dir_json / f"{file_path.stem}.json"
    srs_path = out_dir_srs / f"{file_path.stem}.srs"
    
    data = {"version": 1, "rules": [{rtype: final_rules}]}
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    res = subprocess.run(["sing-box", "rule-set", "compile", str(json_path), "-o", str(srs_path)],
                         capture_output=True, text=True)
    
    if res.returncode != 0:
        raise RuntimeError(f"{file_path.name}: {res.stderr.strip()}")

    return (file_path.name, rtype, len(final_rules))

def run_build_phase():
    console.rule("[bold blue]é˜¶æ®µ 3: ç¼–è¯‘ (.srs)[/bold blue]")

    files = [(p, p.relative_to(DIR_TXT)) for p in DIR_TXT.rglob("*") if p.is_file()]
    if not files:
        console.print("[yellow]âš ï¸ æ²¡æœ‰æ–‡ä»¶éœ€è¦ç¼–è¯‘[/yellow]")
        return

    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]{task.description}"), 
        BarColumn(),
        TaskProgressColumn(),
        TimeElapsedColumn(),
        console=console
    ) as progress:
        task = progress.add_task("[cyan]æ­£åœ¨ç¼–è¯‘...", total=len(files))
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = {executor.submit(compile_file_worker, f): f for f in files}
            
            for future in as_completed(futures):
                try:
                    res = future.result()
                    if res:
                        stats.compile_success += 1
                        stats.total_rules += res[2]
                        stats.details.append(res)
                        progress.update(task, description=f"[cyan]ç¼–è¯‘: {res[0]}")
                    progress.advance(task)
                except Exception as e:
                    stats.compile_fail += 1
                    progress.stop()
                    handle_error("ç¼–è¯‘æ–‡ä»¶", e)

    msg = f"[bold]ç¼–è¯‘æˆåŠŸ[/bold]: [green]{stats.compile_success}[/green]\n[bold]è§„åˆ™æ€»æ•°[/bold]: [cyan]{stats.total_rules:,}[/cyan]\n[bold]è¾“å‡ºç›®å½•[/bold]: {DIR_SRS}"
    console.print(Panel(msg, title="ğŸ”¨ ç¼–è¯‘é˜¶æ®µæ€»ç»“", border_style="green", expand=False))

def main():
    try:
        init_workspace()
        run_sync_phase()
        run_build_phase()
        console.rule("[bold green]âœ¨ å…¨éƒ¨å®Œæˆ âœ¨[/bold green]")
        write_github_summary()
    except KeyboardInterrupt:
        handle_error("ç”¨æˆ·ä¸­æ–­", "æ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        handle_error("æœªæ•è·å¼‚å¸¸", e)

if __name__ == "__main__":
    main()
