import os
import json
import subprocess
import shutil
import tempfile
import re
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# --- é…ç½®éƒ¨åˆ† ---
ROOT_DIR = Path.cwd() # è·å–å½“å‰è„šæœ¬è¿è¡Œçš„æ ¹ç›®å½•
CONFIG_FILE = ROOT_DIR / "repos.json"

# å®šä¹‰è¾“å‡ºç›®å½•
DIR_TXT = ROOT_DIR / "rules-txt"
DIR_JSON = ROOT_DIR / "rules-json"
DIR_SRS = ROOT_DIR / "rules-srs"

# å¹¶å‘çº¿ç¨‹æ•° (æ ¹æ®æœºå™¨æ€§èƒ½è°ƒæ•´ï¼ŒGitHub Actions é€šå¸¸ 2-4 æ ¸)
MAX_WORKERS = 4

def setup_directories():
    """åˆå§‹åŒ–ç›®å½•ç»“æ„"""
    for d in [DIR_TXT, DIR_JSON, DIR_SRS]:
        if d.exists():
            # æ³¨æ„ï¼šè¿™é‡Œé€‰æ‹©æ¸…ç† txt å’Œ josn/srsï¼Œ
            # å¦‚æœä½ æƒ³ä¿ç•™å†å² txtï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ shutil.rmtree(DIR_TXT)
            if d == DIR_TXT: 
                shutil.rmtree(d)
                d.mkdir(parents=True)
            else:
                # ç¼–è¯‘ç›®å½•å»ºè®®æ¯æ¬¡æ¸…ç©º
                shutil.rmtree(d)
                d.mkdir(parents=True)
        else:
            d.mkdir(parents=True)
    print(f"âœ… ç›®å½•åˆå§‹åŒ–å®Œæˆ: \n  - {DIR_TXT}\n  - {DIR_JSON}\n  - {DIR_SRS}")

def sync_repo_task(item):
    """å•ä¸ªä»“åº“åŒæ­¥ä»»åŠ¡"""
    name = item.get('name', 'Unknown')
    url = item.get('url')
    branch = item.get('branch', None) # å¯é€‰åˆ†æ”¯
    remote_tgt = item.get('remote_path')
    local_sub = item.get('local_subdir', 'misc') # é»˜è®¤å­˜å…¥ rules-txt/misc

    if not url or not remote_tgt:
        return f"âŒ [{name}] é…ç½®ç¼ºå¤± url æˆ– remote_path"

    print(f"â¬‡ï¸ [{name}] æ­£åœ¨æ‹‰å–...")
    
    # ç›®æ ‡æœ¬åœ°è·¯å¾„
    dest_dir = DIR_TXT / local_sub
    dest_dir.mkdir(parents=True, exist_ok=True)

    with tempfile.TemporaryDirectory() as temp_dir:
        try:
            cmd = ["git", "clone", "--depth", "1", "--filter=blob:none", "--sparse", url, temp_dir]
            if branch:
                cmd.extend(["-b", branch])
            
            # 1. ç¨€ç–æ‹‰å– (åªæ‹‰å– .git ä¿¡æ¯)
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # 2. è®¾ç½®ç¨€ç–æ£€å‡ºç›®å½•
            subprocess.run(["git", "sparse-checkout", "set", remote_tgt], cwd=temp_dir, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # 3. æ£€å‡ºæ–‡ä»¶
            subprocess.run(["git", "checkout"], cwd=temp_dir, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            # 4. ç§»åŠ¨æ–‡ä»¶
            full_remote_path = Path(temp_dir) / remote_tgt
            
            if full_remote_path.is_dir():
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œéå†å¤åˆ¶
                shutil.copytree(full_remote_path, dest_dir, dirs_exist_ok=True)
            elif full_remote_path.is_file():
                # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                shutil.copy2(full_remote_path, dest_dir)
            else:
                return f"âš ï¸ [{name}] è¿œç¨‹è·¯å¾„æœªæ‰¾åˆ°æ–‡ä»¶: {remote_tgt}"
            
            return f"âœ… [{name}] åŒæ­¥æˆåŠŸ -> {local_sub}"
        
        except subprocess.CalledProcessError:
            return f"âŒ [{name}] Git æ‹‰å–å¤±è´¥"
        except Exception as e:
            return f"âŒ [{name}] æœªçŸ¥é”™è¯¯: {str(e)}"

def parse_and_clean_content(file_path):
    """è¯»å–ã€å»é‡ã€æ¸…æ´—"""
    cleaned_lines = set() # ä½¿ç”¨ set è‡ªåŠ¨å»é‡
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                # ç§»é™¤æ³¨é‡Š
                line = line.split('#')[0].split('//')[0].strip()
                if not line: continue
                
                # ç§»é™¤å¸¸è§çš„å¼•å·å’Œ payload å‰ç¼€
                line = line.replace("'", "").replace('"', "").replace(",", "")
                if line.startswith("payload:"): continue
                if line.startswith("-"): line = line.lstrip("-").strip()
                
                if line:
                    cleaned_lines.add(line)
    except:
        return []
    return list(cleaned_lines)

def detect_rule_type(content_sample, filename):
    """è¯†åˆ«è§„åˆ™ç±»å‹"""
    fname = filename.lower()
    if "ip" in fname and "domain" not in fname: return "ip_cidr"
    if "domain" in fname or "site" in fname: return "domain_suffix"
    
    # å†…å®¹é‡‡æ ·
    ip_pattern = re.compile(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}(/\d+)?$|:')
    ip_count = sum(1 for x in content_sample if ip_pattern.match(x))
    return "ip_cidr" if ip_count > len(content_sample) / 2 else "domain_suffix"

def compile_worker(file_info):
    """å•ä¸ªæ–‡ä»¶ç¼–è¯‘ä»»åŠ¡ (ç”¨äºå¤šçº¿ç¨‹)"""
    file_path, rel_path = file_info
    
    # è¿‡æ»¤éè§„åˆ™æ–‡ä»¶
    if file_path.suffix not in ['.txt', '.list', '.yaml', '.conf', '.json', '']:
        return None

    # 1. è§£æ
    content = parse_and_clean_content(file_path)
    if not content: return None

    # 2. è¯†åˆ«
    rule_type = detect_rule_type(content[:20], file_path.name)
    
    # 3. æ„é€  JSON
    data = {"version": 1, "rules": [{rule_type: content}]}
    
    base_name = file_path.stem
    target_subdir = rel_path.parent
    
    # å‡†å¤‡è¾“å‡ºç›®å½•
    json_dir = DIR_JSON / target_subdir
    srs_dir = DIR_SRS / target_subdir
    json_dir.mkdir(parents=True, exist_ok=True)
    srs_dir.mkdir(parents=True, exist_ok=True)
    
    json_out = json_dir / f"{base_name}.json"
    srs_out = srs_dir / f"{base_name}.srs"
    
    # 4. å†™å…¥ JSON
    try:
        with open(json_out, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"âŒ JSON å†™é”™: {file_path.name} - {e}"

    # 5. è°ƒç”¨ Sing-box ç¼–è¯‘
    try:
        proc = subprocess.run(
            ["sing-box", "rule-set", "compile", str(json_out), "-o", str(srs_out)],
            capture_output=True, text=True
        )
        if proc.returncode != 0:
            return f"âŒ SRS ç¼–è¯‘å¤±è´¥: {file_path.name} -> {proc.stderr.strip()}"
    except Exception as e:
        return f"âŒ Sing-box è°ƒç”¨å¤±è´¥: {e}"

    return f"âœ¨ å®Œæˆ: {rel_path} ({len(content)} rules) -> {rule_type}"

def main():
    if not CONFIG_FILE.exists():
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ {CONFIG_FILE}")
        exit(1)

    print(">>> [æ­¥éª¤ 1] åˆå§‹åŒ–ä¸åŒæ­¥...")
    setup_directories()
    
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        repo_list = json.load(f)

    # ä¸²è¡Œæ‹‰å–ï¼ˆGit å¹¶å‘å®¹æ˜“é”æ–‡ä»¶ï¼Œå»ºè®®ä¸²è¡Œæˆ–é™åˆ¶ä½å¹¶å‘ï¼‰
    for item in repo_list:
        print(sync_repo_task(item))

    print("\n>>> [æ­¥éª¤ 2] ç¼–è¯‘è§„åˆ™é›† (å¹¶å‘å¤„ç†)...")
    
    # æ”¶é›†å¾…å¤„ç†æ–‡ä»¶
    all_files = []
    for p in DIR_TXT.rglob("*"):
        if p.is_file():
            # è®¡ç®—ç›¸å¯¹äº DIR_TXT çš„è·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æ„
            all_files.append((p, p.relative_to(DIR_TXT)))

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ç¼–è¯‘
    success_cnt = 0
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        results = executor.map(compile_worker, all_files)
        for res in results:
            if res:
                print(res)
                if "âŒ" not in res: success_cnt += 1

    print(f"\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆ! æˆåŠŸç”Ÿæˆ {success_cnt} ä¸ª SRS è§„åˆ™é›†ã€‚")

if __name__ == "__main__":
    main()
